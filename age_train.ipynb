{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas\n",
    "# ! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING THE PREPROCESSED DATA - CONTAINING IMAGES TOO\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('withpixel_gender.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[17/10000217_1981-05-05_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[12/100012_1948-07-03_2008.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>[92.0, 97.0, 91.0, 89.0, 94.0, 90.0, 91.0, 96....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[16/10002116_1971-05-31_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>[61.0, 30.0, 10.0, 61.0, 30.0, 10.0, 61.0, 30....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[02/10002702_1960-11-09_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>[97.0, 122.0, 178.0, 97.0, 122.0, 178.0, 97.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[41/10003541_1937-09-27_1971.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>[190.0, 189.0, 194.0, 204.0, 203.0, 208.0, 203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62321</th>\n",
       "      <td>[38/9996938_1937-02-15_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>[71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62322</th>\n",
       "      <td>[46/9996946_1943-11-01_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>[54.0, 54.0, 54.0, 44.0, 44.0, 44.0, 28.0, 28....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62323</th>\n",
       "      <td>[49/9996949_1937-04-17_1963.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>[41.0, 41.0, 41.0, 29.0, 29.0, 29.0, 22.0, 22....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62325</th>\n",
       "      <td>[09/9998109_1972-12-27_2013.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>[137.0, 174.0, 94.0, 137.0, 174.0, 94.0, 137.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62327</th>\n",
       "      <td>[80/999980_1954-06-11_2008.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>[35.0, 36.0, 18.0, 35.0, 36.0, 18.0, 36.0, 37....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39382 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               full_path  gender  age  \\\n",
       "0      [17/10000217_1981-05-05_2009.jpg]     1.0   28   \n",
       "2        [12/100012_1948-07-03_2008.jpg]     1.0   60   \n",
       "4      [16/10002116_1971-05-31_2012.jpg]     0.0   41   \n",
       "5      [02/10002702_1960-11-09_2012.jpg]     0.0   52   \n",
       "6      [41/10003541_1937-09-27_1971.jpg]     1.0   34   \n",
       "...                                  ...     ...  ...   \n",
       "62321   [38/9996938_1937-02-15_1968.jpg]     1.0   31   \n",
       "62322   [46/9996946_1943-11-01_1968.jpg]     1.0   25   \n",
       "62323   [49/9996949_1937-04-17_1963.jpg]     1.0   26   \n",
       "62325   [09/9998109_1972-12-27_2013.jpg]     1.0   41   \n",
       "62327    [80/999980_1954-06-11_2008.jpg]     0.0   54   \n",
       "\n",
       "                                                  pixels  \n",
       "0      [255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255...  \n",
       "2      [92.0, 97.0, 91.0, 89.0, 94.0, 90.0, 91.0, 96....  \n",
       "4      [61.0, 30.0, 10.0, 61.0, 30.0, 10.0, 61.0, 30....  \n",
       "5      [97.0, 122.0, 178.0, 97.0, 122.0, 178.0, 97.0,...  \n",
       "6      [190.0, 189.0, 194.0, 204.0, 203.0, 208.0, 203...  \n",
       "...                                                  ...  \n",
       "62321  [71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71....  \n",
       "62322  [54.0, 54.0, 54.0, 44.0, 44.0, 44.0, 28.0, 28....  \n",
       "62323  [41.0, 41.0, 41.0, 29.0, 29.0, 29.0, 22.0, 22....  \n",
       "62325  [137.0, 174.0, 94.0, 137.0, 174.0, 94.0, 137.0...  \n",
       "62327  [35.0, 36.0, 18.0, 35.0, 36.0, 18.0, 36.0, 37....  \n",
       "\n",
       "[39382 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "full path - the path of image file\n",
    "gender - 0,1 denoting male female\n",
    "age - the category of the person with age group\n",
    "pixels - image encoded as matrix in dataframe\n",
    "\"\"\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done - given number of features collected\n"
     ]
    }
   ],
   "source": [
    "classes = 101 # 0 to 100\n",
    "target = df['age'].values\n",
    "target_classes = keras.utils.to_categorical(target, classes)\n",
    "\n",
    "features = []\n",
    "\n",
    "# limiting the target classes, and featues to limit memory usage\n",
    "# both target and feature must match with the split dataset \n",
    "limit_dataset = 10000\n",
    "\n",
    "target_classes = target_classes[:limit_dataset]\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    features.append(df['pixels'].values[i])\n",
    "    if len(features)=>limit_dataset:\n",
    "        print('Done - decided number of features are collected')\n",
    "        break\n",
    "\n",
    "# convering the list into numpy - that can be used for batch training\n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managing splits in dataset for training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, target_classes, test_size=0.30)\n",
    "\n",
    "print(len(features))\n",
    "print(len(target_classes))\n",
    "print(len(train_x),len(test__x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since memory consumption is very high -we need to delete the df to get it back\n",
    "# del df\n",
    "# del features # 20 gb ram freeedddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if loading and saving the features from direct pkl to avoid using pandas\n",
    "# dataframe already has pickle loader so no problem to import pickle\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# with open('image_features.pickle', 'wb') as handle:\n",
    "#     pickle.dump(features, handle)\n",
    "    \n",
    "# with open('gender_target.pickle', 'wb') as handle:\n",
    "#     pickle.dump(target_gender, handle)\n",
    "    \n",
    "# with open('age_target.pickle', 'wb') as handle:\n",
    "#     pickle.dump(target, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the base VGG Face Model\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "\n",
    "# vgg-face model \n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1), input_shape=(224,224,3)))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128,(3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7,7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1,1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained vgg weights availble on drive\n",
    "# you can find it here: https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "\n",
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d (ZeroPadding2 (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 1, 1, 2622)        10742334  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2622)              0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2622)              0         \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the last layers of network to get 100 predictions for classes\n",
    "# \n",
    "\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# lock the layer weights for early layers \n",
    "# - they could already detect some patterns\n",
    "# fitting the network from scratch might cause to lose this info\n",
    "# freeze all layers except last 3 conv layers - 2622 units\n",
    "# just 101 units for age prediction task\n",
    "# then add custom layer for 101 layers\n",
    "\n",
    "# to not lose the training done before in pretrained weights\n",
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "base_model_output = Sequential()\n",
    "base_model_output = Convolution2D(101, (1,1), name='predictions')(model.layers[-4].output)\n",
    "base_model_output = Flatten()(base_model_output)\n",
    "base_model_output = Activation('softmax')(base_model_output)\n",
    "\n",
    "age_model = Model(inputs=model.input, outputs=base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_input (InputL [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "predictions (Conv2D)         (None, 1, 1, 101)         413797    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 101)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 134,674,341\n",
      "Trainable params: 119,959,653\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "age_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3887 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0185s vs `on_train_batch_end` time: 0.2852s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.7666 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from inf to 4.37888, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.7666 - accuracy: 0.0391 - val_loss: 4.3789 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4326 - accuracy: 0.0352\n",
      "Epoch 00002: val_loss improved from 4.37888 to 4.37638, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.4326 - accuracy: 0.0352 - val_loss: 4.3764 - val_accuracy: 0.0393\n",
      "epoch 1\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.4667 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0263s vs `on_train_batch_end` time: 0.2803s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4462 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.37638 to 4.37163, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 35s 4s/step - loss: 4.4462 - accuracy: 0.0430 - val_loss: 4.3716 - val_accuracy: 0.0397\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5003 - accuracy: 0.0430\n",
      "Epoch 00002: val_loss improved from 4.37163 to 4.37106, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.5003 - accuracy: 0.0430 - val_loss: 4.3711 - val_accuracy: 0.0393\n",
      "epoch 2\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.3346 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0191s vs `on_train_batch_end` time: 0.3620s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3779 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.37106 to 4.36830, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.3779 - accuracy: 0.0430 - val_loss: 4.3683 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4411 - accuracy: 0.0430\n",
      "Epoch 00002: val_loss improved from 4.36830 to 4.36550, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 29s 4s/step - loss: 4.4411 - accuracy: 0.0430 - val_loss: 4.3655 - val_accuracy: 0.0393\n",
      "epoch 3\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.8595 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0122s vs `on_train_batch_end` time: 0.2927s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.6195 - accuracy: 0.0195\n",
      "Epoch 00001: val_loss improved from 4.36550 to 4.36275, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 35s 4s/step - loss: 4.6195 - accuracy: 0.0195 - val_loss: 4.3627 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5957 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.36275 to 4.36020, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.5957 - accuracy: 0.0312 - val_loss: 4.3602 - val_accuracy: 0.0393\n",
      "epoch 4\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3769 - accuracy: 0.0312    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0201s vs `on_train_batch_end` time: 0.2962s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4083 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from 4.36020 to 4.35771, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 35s 4s/step - loss: 4.4083 - accuracy: 0.0273 - val_loss: 4.3577 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3806 - accuracy: 0.0273\n",
      "Epoch 00002: val_loss improved from 4.35771 to 4.35530, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.3806 - accuracy: 0.0273 - val_loss: 4.3553 - val_accuracy: 0.0393\n",
      "epoch 5\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.5211 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0388s vs `on_train_batch_end` time: 0.2868s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4044 - accuracy: 0.0508\n",
      "Epoch 00001: val_loss improved from 4.35530 to 4.35280, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.4044 - accuracy: 0.0508 - val_loss: 4.3528 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3774 - accuracy: 0.0508\n",
      "Epoch 00002: val_loss improved from 4.35280 to 4.35025, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.3774 - accuracy: 0.0508 - val_loss: 4.3502 - val_accuracy: 0.0393\n",
      "epoch 6\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3323 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0204s vs `on_train_batch_end` time: 0.2949s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4014 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.35025 to 4.34768, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.4014 - accuracy: 0.0352 - val_loss: 4.3477 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4281 - accuracy: 0.0352\n",
      "Epoch 00002: val_loss improved from 4.34768 to 4.34514, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.4281 - accuracy: 0.0352 - val_loss: 4.3451 - val_accuracy: 0.0393\n",
      "epoch 7\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.3468 - accuracy: 0.0312    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0201s vs `on_train_batch_end` time: 0.2924s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3601 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.34514 to 4.34258, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 35s 4s/step - loss: 4.3601 - accuracy: 0.0312 - val_loss: 4.3426 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3361 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.34258 to 4.34002, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.3361 - accuracy: 0.0312 - val_loss: 4.3400 - val_accuracy: 0.0393\n",
      "epoch 8\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3125 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0229s vs `on_train_batch_end` time: 0.2920s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3174 - accuracy: 0.0547\n",
      "Epoch 00001: val_loss improved from 4.34002 to 4.33739, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.3174 - accuracy: 0.0547 - val_loss: 4.3374 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3372 - accuracy: 0.0586\n",
      "Epoch 00002: val_loss improved from 4.33739 to 4.33473, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.3372 - accuracy: 0.0586 - val_loss: 4.3347 - val_accuracy: 0.0393\n",
      "epoch 9\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.5795 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0162s vs `on_train_batch_end` time: 0.2986s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 4.4042 - accuracy: 0.0547\n",
      "Epoch 00001: val_loss improved from 4.33473 to 4.33218, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.4042 - accuracy: 0.0547 - val_loss: 4.3322 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3428 - accuracy: 0.0547\n",
      "Epoch 00002: val_loss improved from 4.33218 to 4.32963, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.3428 - accuracy: 0.0547 - val_loss: 4.3296 - val_accuracy: 0.0393\n",
      "epoch 10\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3471 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0242s vs `on_train_batch_end` time: 0.2909s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3330 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from 4.32963 to 4.32717, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 35s 4s/step - loss: 4.3330 - accuracy: 0.0273 - val_loss: 4.3272 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4470 - accuracy: 0.0273\n",
      "Epoch 00002: val_loss improved from 4.32717 to 4.32475, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.4470 - accuracy: 0.0273 - val_loss: 4.3247 - val_accuracy: 0.0393\n",
      "epoch 11\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.4461 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0143s vs `on_train_batch_end` time: 0.2982s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3396 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.32475 to 4.32218, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.3396 - accuracy: 0.0430 - val_loss: 4.3222 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3286 - accuracy: 0.0469\n",
      "Epoch 00002: val_loss improved from 4.32218 to 4.31959, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.3286 - accuracy: 0.0469 - val_loss: 4.3196 - val_accuracy: 0.0393\n",
      "epoch 12\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3358 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0177s vs `on_train_batch_end` time: 0.2912s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3220 - accuracy: 0.0664\n",
      "Epoch 00001: val_loss improved from 4.31959 to 4.31705, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.3220 - accuracy: 0.0664 - val_loss: 4.3171 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3188 - accuracy: 0.0664\n",
      "Epoch 00002: val_loss improved from 4.31705 to 4.31463, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.3188 - accuracy: 0.0664 - val_loss: 4.3146 - val_accuracy: 0.0393\n",
      "epoch 13\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3785 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0393s vs `on_train_batch_end` time: 0.2932s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3185 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.31463 to 4.31234, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.3185 - accuracy: 0.0312 - val_loss: 4.3123 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3022 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.31234 to 4.31006, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.3022 - accuracy: 0.0312 - val_loss: 4.3101 - val_accuracy: 0.0393\n",
      "epoch 14\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.3586 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0240s vs `on_train_batch_end` time: 0.2881s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.9967 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.31006 to 4.30783, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.9967 - accuracy: 0.0469 - val_loss: 4.3078 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3523 - accuracy: 0.0430\n",
      "Epoch 00002: val_loss improved from 4.30783 to 4.30566, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 25s 3s/step - loss: 4.3523 - accuracy: 0.0430 - val_loss: 4.3057 - val_accuracy: 0.0393\n",
      "epoch 15\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3154 - accuracy: 0.0312    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0253s vs `on_train_batch_end` time: 0.2939s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3286 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.30566 to 4.30545, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.3286 - accuracy: 0.0312 - val_loss: 4.3055 - val_accuracy: 0.0400\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4879 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.30545 to 4.30127, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.4879 - accuracy: 0.0312 - val_loss: 4.3013 - val_accuracy: 0.0393\n",
      "epoch 16\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2464 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0137s vs `on_train_batch_end` time: 0.2982s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4963 - accuracy: 0.0664\n",
      "Epoch 00001: val_loss improved from 4.30127 to 4.29904, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.4963 - accuracy: 0.0664 - val_loss: 4.2990 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.0563 - accuracy: 0.0625\n",
      "Epoch 00002: val_loss improved from 4.29904 to 4.29693, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 5.0563 - accuracy: 0.0625 - val_loss: 4.2969 - val_accuracy: 0.0393\n",
      "epoch 17\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2802 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0222s vs `on_train_batch_end` time: 0.2899s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3340 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.29693 to 4.29475, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.3340 - accuracy: 0.0352 - val_loss: 4.2947 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3080 - accuracy: 0.0352\n",
      "Epoch 00002: val_loss improved from 4.29475 to 4.29247, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.3080 - accuracy: 0.0352 - val_loss: 4.2925 - val_accuracy: 0.0393\n",
      "epoch 18\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3472 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.2946s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3335 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.29247 to 4.29036, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.3335 - accuracy: 0.0469 - val_loss: 4.2904 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 4.3784 - accuracy: 0.0469\n",
      "Epoch 00002: val_loss improved from 4.29036 to 4.28837, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.3784 - accuracy: 0.0469 - val_loss: 4.2884 - val_accuracy: 0.0393\n",
      "epoch 19\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 5.5186 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0181s vs `on_train_batch_end` time: 0.2960s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.2965 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.28837 to 4.28649, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 5.2965 - accuracy: 0.0352 - val_loss: 4.2865 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3663 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.28649 to 4.28467, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.3663 - accuracy: 0.0391 - val_loss: 4.2847 - val_accuracy: 0.0393\n",
      "epoch 20\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.4511 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0181s vs `on_train_batch_end` time: 0.2964s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4788 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.28467 to 4.28275, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.4788 - accuracy: 0.0391 - val_loss: 4.2828 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3184 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.28275 to 4.28074, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.3184 - accuracy: 0.0391 - val_loss: 4.2807 - val_accuracy: 0.0393\n",
      "epoch 21\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.2509 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0205s vs `on_train_batch_end` time: 0.2934s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3303 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.28074 to 4.27872, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.3303 - accuracy: 0.0352 - val_loss: 4.2787 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3912 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.27872 to 4.27670, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.3912 - accuracy: 0.0391 - val_loss: 4.2767 - val_accuracy: 0.0393\n",
      "epoch 22\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2901 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0254s vs `on_train_batch_end` time: 0.2890s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3531 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.27670 to 4.27470, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.3531 - accuracy: 0.0352 - val_loss: 4.2747 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.1463 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.27470 to 4.27278, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 5.1463 - accuracy: 0.0312 - val_loss: 4.2728 - val_accuracy: 0.0393\n",
      "epoch 23\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 5.4054 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0187s vs `on_train_batch_end` time: 0.2901s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.6516 - accuracy: 0.0195\n",
      "Epoch 00001: val_loss improved from 4.27278 to 4.27088, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.6516 - accuracy: 0.0195 - val_loss: 4.2709 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3294 - accuracy: 0.0195\n",
      "Epoch 00002: val_loss improved from 4.27088 to 4.26900, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.3294 - accuracy: 0.0195 - val_loss: 4.2690 - val_accuracy: 0.0393\n",
      "epoch 24\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3166 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0163s vs `on_train_batch_end` time: 0.3009s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3530 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.26900 to 4.26719, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.3530 - accuracy: 0.0391 - val_loss: 4.2672 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.9735 - accuracy: 0.0430\n",
      "Epoch 00002: val_loss improved from 4.26719 to 4.26542, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.9735 - accuracy: 0.0430 - val_loss: 4.2654 - val_accuracy: 0.0393\n",
      "epoch 25\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3051 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0203s vs `on_train_batch_end` time: 0.2938s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3601 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.26542 to 4.26364, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.3601 - accuracy: 0.0430 - val_loss: 4.2636 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2926 - accuracy: 0.0430\n",
      "Epoch 00002: val_loss improved from 4.26364 to 4.26186, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.2926 - accuracy: 0.0430 - val_loss: 4.2619 - val_accuracy: 0.0393\n",
      "epoch 26\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3091 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0132s vs `on_train_batch_end` time: 0.3011s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5131 - accuracy: 0.0508\n",
      "Epoch 00001: val_loss improved from 4.26186 to 4.26014, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.5131 - accuracy: 0.0508 - val_loss: 4.2601 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4341 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.26014 to 4.25830, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.4341 - accuracy: 0.0391 - val_loss: 4.2583 - val_accuracy: 0.0393\n",
      "epoch 27\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.8745 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0190s vs `on_train_batch_end` time: 0.2963s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.7927 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.25830 to 4.25650, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.7927 - accuracy: 0.0430 - val_loss: 4.2565 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4515 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.25650 to 4.25465, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.4515 - accuracy: 0.0391 - val_loss: 4.2547 - val_accuracy: 0.0393\n",
      "epoch 28\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2445 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0145s vs `on_train_batch_end` time: 0.2946s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2533 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.25465 to 4.25286, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.2533 - accuracy: 0.0430 - val_loss: 4.2529 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.8084 - accuracy: 0.0430\n",
      "Epoch 00002: val_loss improved from 4.25286 to 4.25104, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.8084 - accuracy: 0.0430 - val_loss: 4.2510 - val_accuracy: 0.0393\n",
      "epoch 29\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2461 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0231s vs `on_train_batch_end` time: 0.2897s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2384 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.25104 to 4.24930, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.2384 - accuracy: 0.0430 - val_loss: 4.2493 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.2249 - accuracy: 0.0234\n",
      "Epoch 00002: val_loss improved from 4.24930 to 4.24754, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 5.2249 - accuracy: 0.0234 - val_loss: 4.2475 - val_accuracy: 0.0393\n",
      "epoch 30\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2928 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0207s vs `on_train_batch_end` time: 0.2934s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4052 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.24754 to 4.24583, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.4052 - accuracy: 0.0312 - val_loss: 4.2458 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.7277 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.24583 to 4.24420, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.7277 - accuracy: 0.0312 - val_loss: 4.2442 - val_accuracy: 0.0393\n",
      "epoch 31\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3519 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0215s vs `on_train_batch_end` time: 0.2900s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3123 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.24420 to 4.24261, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.3123 - accuracy: 0.0391 - val_loss: 4.2426 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2647 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.24261 to 4.24102, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2647 - accuracy: 0.0391 - val_loss: 4.2410 - val_accuracy: 0.0393\n",
      "epoch 32\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2077 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0209s vs `on_train_batch_end` time: 0.3051s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3299 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss did not improve from 4.24102\n",
      "8/8 [==============================] - 27s 3s/step - loss: 4.3299 - accuracy: 0.0469 - val_loss: 4.4580 - val_accuracy: 0.0293\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5400 - accuracy: 0.0469\n",
      "Epoch 00002: val_loss improved from 4.24102 to 4.23772, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.5400 - accuracy: 0.0469 - val_loss: 4.2377 - val_accuracy: 0.0393\n",
      "epoch 33\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2559 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0190s vs `on_train_batch_end` time: 0.2976s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3359 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.23772 to 4.23617, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.3359 - accuracy: 0.0352 - val_loss: 4.2362 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3040 - accuracy: 0.0352\n",
      "Epoch 00002: val_loss improved from 4.23617 to 4.23481, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.3040 - accuracy: 0.0352 - val_loss: 4.2348 - val_accuracy: 0.0393\n",
      "epoch 34\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2683 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0202s vs `on_train_batch_end` time: 0.2945s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2956 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.23481 to 4.23354, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.2956 - accuracy: 0.0469 - val_loss: 4.2335 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2532 - accuracy: 0.0469\n",
      "Epoch 00002: val_loss improved from 4.23354 to 4.23215, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.2532 - accuracy: 0.0469 - val_loss: 4.2322 - val_accuracy: 0.0393\n",
      "epoch 35\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2314 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0210s vs `on_train_batch_end` time: 0.2924s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.0001 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from 4.23215 to 4.23075, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 5.0001 - accuracy: 0.0273 - val_loss: 4.2308 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2395 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.23075 to 4.22928, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 29s 4s/step - loss: 4.2395 - accuracy: 0.0312 - val_loss: 4.2293 - val_accuracy: 0.0393\n",
      "epoch 36\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2115 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0195s vs `on_train_batch_end` time: 0.2936s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.6689 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.22928 to 4.22788, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 5.6689 - accuracy: 0.0312 - val_loss: 4.2279 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2965 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.22788 to 4.22651, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2965 - accuracy: 0.0312 - val_loss: 4.2265 - val_accuracy: 0.0393\n",
      "epoch 37\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.6099 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0179s vs `on_train_batch_end` time: 0.2939s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3612 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.22651 to 4.22511, saving model to age_model.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 34s 4s/step - loss: 4.3612 - accuracy: 0.0391 - val_loss: 4.2251 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2869 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.22511 to 4.22375, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2869 - accuracy: 0.0391 - val_loss: 4.2238 - val_accuracy: 0.0393\n",
      "epoch 38\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3524 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0191s vs `on_train_batch_end` time: 0.2906s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2566 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.22375 to 4.22237, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.2566 - accuracy: 0.0352 - val_loss: 4.2224 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2958 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.22237 to 4.22098, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.2958 - accuracy: 0.0312 - val_loss: 4.2210 - val_accuracy: 0.0393\n",
      "epoch 39\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.7439 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0208s vs `on_train_batch_end` time: 0.2903s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3489 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.22098 to 4.21956, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.3489 - accuracy: 0.0352 - val_loss: 4.2196 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2768 - accuracy: 0.0352\n",
      "Epoch 00002: val_loss improved from 4.21956 to 4.21812, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2768 - accuracy: 0.0352 - val_loss: 4.2181 - val_accuracy: 0.0393\n",
      "epoch 40\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1770 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0237s vs `on_train_batch_end` time: 0.2900s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2414 - accuracy: 0.0195\n",
      "Epoch 00001: val_loss improved from 4.21812 to 4.21669, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.2414 - accuracy: 0.0195 - val_loss: 4.2167 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2532 - accuracy: 0.0195\n",
      "Epoch 00002: val_loss improved from 4.21669 to 4.21533, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2532 - accuracy: 0.0195 - val_loss: 4.2153 - val_accuracy: 0.0393\n",
      "epoch 41\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1599 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0302s vs `on_train_batch_end` time: 0.2844s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2292 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.21533 to 4.21395, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.2292 - accuracy: 0.0391 - val_loss: 4.2139 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2385 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.21395 to 4.21260, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2385 - accuracy: 0.0391 - val_loss: 4.2126 - val_accuracy: 0.0393\n",
      "epoch 42\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1826 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0183s vs `on_train_batch_end` time: 0.2973s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1886 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from 4.21260 to 4.21118, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.1886 - accuracy: 0.0273 - val_loss: 4.2112 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1767 - accuracy: 0.0273\n",
      "Epoch 00002: val_loss improved from 4.21118 to 4.20979, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.1767 - accuracy: 0.0273 - val_loss: 4.2098 - val_accuracy: 0.0393\n",
      "epoch 43\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1691 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0204s vs `on_train_batch_end` time: 0.2893s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2026 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.20979 to 4.20836, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.2026 - accuracy: 0.0430 - val_loss: 4.2084 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2008 - accuracy: 0.0430\n",
      "Epoch 00002: val_loss improved from 4.20836 to 4.20698, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2008 - accuracy: 0.0430 - val_loss: 4.2070 - val_accuracy: 0.0393\n",
      "epoch 44\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2168 - accuracy: 0.0312    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0171s vs `on_train_batch_end` time: 0.2987s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2217 - accuracy: 0.0508\n",
      "Epoch 00001: val_loss improved from 4.20698 to 4.20565, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.2217 - accuracy: 0.0508 - val_loss: 4.2057 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2410 - accuracy: 0.0508\n",
      "Epoch 00002: val_loss improved from 4.20565 to 4.20440, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2410 - accuracy: 0.0508 - val_loss: 4.2044 - val_accuracy: 0.0393\n",
      "epoch 45\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1478 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0169s vs `on_train_batch_end` time: 0.2957s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2378 - accuracy: 0.0156\n",
      "Epoch 00001: val_loss improved from 4.20440 to 4.20312, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.2378 - accuracy: 0.0156 - val_loss: 4.2031 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3538 - accuracy: 0.0156\n",
      "Epoch 00002: val_loss improved from 4.20312 to 4.20185, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 29s 4s/step - loss: 4.3538 - accuracy: 0.0156 - val_loss: 4.2018 - val_accuracy: 0.0393\n",
      "epoch 46\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1327 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0198s vs `on_train_batch_end` time: 0.2926s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 6.5075 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.20185 to 4.20063, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 6.5075 - accuracy: 0.0469 - val_loss: 4.2006 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2953 - accuracy: 0.0430\n",
      "Epoch 00002: val_loss improved from 4.20063 to 4.19956, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.2953 - accuracy: 0.0430 - val_loss: 4.1996 - val_accuracy: 0.0393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2233 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0161s vs `on_train_batch_end` time: 0.2983s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2080 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from 4.19956 to 4.19844, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.2080 - accuracy: 0.0273 - val_loss: 4.1984 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5234 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss did not improve from 4.19844\n",
      "8/8 [==============================] - 25s 3s/step - loss: 4.5234 - accuracy: 0.0391 - val_loss: 4.1995 - val_accuracy: 0.0383\n",
      "epoch 48\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.9295 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0168s vs `on_train_batch_end` time: 0.2969s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4095 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.19844 to 4.19618, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.4095 - accuracy: 0.0469 - val_loss: 4.1962 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1928 - accuracy: 0.0273\n",
      "Epoch 00002: val_loss improved from 4.19618 to 4.19500, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.1928 - accuracy: 0.0273 - val_loss: 4.1950 - val_accuracy: 0.0393\n",
      "epoch 49\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2312 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0238s vs `on_train_batch_end` time: 0.2965s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1998 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.19500 to 4.19385, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.1998 - accuracy: 0.0312 - val_loss: 4.1938 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2404 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.19385 to 4.19268, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2404 - accuracy: 0.0312 - val_loss: 4.1927 - val_accuracy: 0.0393\n",
      "epoch 50\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2123 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0160s vs `on_train_batch_end` time: 0.2999s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2087 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.19268 to 4.19157, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.2087 - accuracy: 0.0352 - val_loss: 4.1916 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.6747 - accuracy: 0.0352\n",
      "Epoch 00002: val_loss improved from 4.19157 to 4.19052, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.6747 - accuracy: 0.0352 - val_loss: 4.1905 - val_accuracy: 0.0393\n",
      "epoch 51\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2422 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0215s vs `on_train_batch_end` time: 0.2944s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2236 - accuracy: 0.0547\n",
      "Epoch 00001: val_loss improved from 4.19052 to 4.18950, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.2236 - accuracy: 0.0547 - val_loss: 4.1895 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2200 - accuracy: 0.0547\n",
      "Epoch 00002: val_loss improved from 4.18950 to 4.18858, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2200 - accuracy: 0.0547 - val_loss: 4.1886 - val_accuracy: 0.0393\n",
      "epoch 52\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1980 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0217s vs `on_train_batch_end` time: 0.2948s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1996 - accuracy: 0.0586\n",
      "Epoch 00001: val_loss improved from 4.18858 to 4.18758, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.1996 - accuracy: 0.0586 - val_loss: 4.1876 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.1964 - accuracy: 0.0586\n",
      "Epoch 00002: val_loss improved from 4.18758 to 4.18648, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 5.1964 - accuracy: 0.0586 - val_loss: 4.1865 - val_accuracy: 0.0393\n",
      "epoch 53\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.2870 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0157s vs `on_train_batch_end` time: 0.3246s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2294 - accuracy: 0.0508\n",
      "Epoch 00001: val_loss improved from 4.18648 to 4.18541, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.2294 - accuracy: 0.0508 - val_loss: 4.1854 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2885 - accuracy: 0.0547\n",
      "Epoch 00002: val_loss improved from 4.18541 to 4.18438, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.2885 - accuracy: 0.0547 - val_loss: 4.1844 - val_accuracy: 0.0393\n",
      "epoch 54\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.0917 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0227s vs `on_train_batch_end` time: 0.2939s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1664 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.18438 to 4.18330, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.1664 - accuracy: 0.0469 - val_loss: 4.1833 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1643 - accuracy: 0.0469\n",
      "Epoch 00002: val_loss improved from 4.18330 to 4.18217, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 29s 4s/step - loss: 4.1643 - accuracy: 0.0469 - val_loss: 4.1822 - val_accuracy: 0.0393\n",
      "epoch 55\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1965 - accuracy: 0.0312    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0142s vs `on_train_batch_end` time: 0.2996s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2017 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.18217 to 4.18112, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.2017 - accuracy: 0.0391 - val_loss: 4.1811 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2111 - accuracy: 0.0352\n",
      "Epoch 00002: val_loss improved from 4.18112 to 4.18013, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2111 - accuracy: 0.0352 - val_loss: 4.1801 - val_accuracy: 0.0393\n",
      "epoch 56\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1362 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0180s vs `on_train_batch_end` time: 0.3033s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 4.1900 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.18013 to 4.17905, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.1900 - accuracy: 0.0312 - val_loss: 4.1790 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1856 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.17905 to 4.17793, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.1856 - accuracy: 0.0312 - val_loss: 4.1779 - val_accuracy: 0.0393\n",
      "epoch 57\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2023 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0177s vs `on_train_batch_end` time: 0.2949s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1922 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.17793 to 4.17687, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.1922 - accuracy: 0.0312 - val_loss: 4.1769 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1905 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.17687 to 4.17591, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.1905 - accuracy: 0.0312 - val_loss: 4.1759 - val_accuracy: 0.0393\n",
      "epoch 58\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.3397 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0153s vs `on_train_batch_end` time: 0.2967s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2296 - accuracy: 0.0234\n",
      "Epoch 00001: val_loss improved from 4.17591 to 4.17492, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.2296 - accuracy: 0.0234 - val_loss: 4.1749 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2093 - accuracy: 0.0234\n",
      "Epoch 00002: val_loss improved from 4.17492 to 4.17396, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2093 - accuracy: 0.0234 - val_loss: 4.1740 - val_accuracy: 0.0393\n",
      "epoch 59\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1567 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0163s vs `on_train_batch_end` time: 0.2978s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1453 - accuracy: 0.0508\n",
      "Epoch 00001: val_loss improved from 4.17396 to 4.17297, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.1453 - accuracy: 0.0508 - val_loss: 4.1730 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1466 - accuracy: 0.0508\n",
      "Epoch 00002: val_loss improved from 4.17297 to 4.17196, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.1466 - accuracy: 0.0508 - val_loss: 4.1720 - val_accuracy: 0.0393\n",
      "epoch 60\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2067 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0207s vs `on_train_batch_end` time: 0.2968s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1788 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.17196 to 4.17096, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.1788 - accuracy: 0.0312 - val_loss: 4.1710 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1756 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.17096 to 4.16999, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.1756 - accuracy: 0.0312 - val_loss: 4.1700 - val_accuracy: 0.0393\n",
      "epoch 61\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1107 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0214s vs `on_train_batch_end` time: 0.2888s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1345 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.16999 to 4.16895, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.1345 - accuracy: 0.0430 - val_loss: 4.1689 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1345 - accuracy: 0.0430\n",
      "Epoch 00002: val_loss improved from 4.16895 to 4.16786, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.1345 - accuracy: 0.0430 - val_loss: 4.1679 - val_accuracy: 0.0393\n",
      "epoch 62\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.5653 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0211s vs `on_train_batch_end` time: 0.2974s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2596 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.16786 to 4.16679, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.2596 - accuracy: 0.0391 - val_loss: 4.1668 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1490 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.16679 to 4.16575, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.1490 - accuracy: 0.0391 - val_loss: 4.1658 - val_accuracy: 0.0393\n",
      "epoch 63\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.0456 - accuracy: 0.0625    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0123s vs `on_train_batch_end` time: 0.2982s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.7278 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.16575 to 4.16478, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.7278 - accuracy: 0.0391 - val_loss: 4.1648 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2025 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.16478 to 4.16391, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2025 - accuracy: 0.0391 - val_loss: 4.1639 - val_accuracy: 0.0393\n",
      "epoch 64\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.1476 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0232s vs `on_train_batch_end` time: 0.2916s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1398 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from 4.16391 to 4.16304, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.1398 - accuracy: 0.0273 - val_loss: 4.1630 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.8266 - accuracy: 0.0273\n",
      "Epoch 00002: val_loss improved from 4.16304 to 4.16214, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.8266 - accuracy: 0.0273 - val_loss: 4.1621 - val_accuracy: 0.0393\n",
      "epoch 65\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2283 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0180s vs `on_train_batch_end` time: 0.2972s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4701 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.16214 to 4.16127, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.4701 - accuracy: 0.0469 - val_loss: 4.1613 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - ETA: 0s - loss: 4.5622 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.16127 to 4.16037, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.5622 - accuracy: 0.0391 - val_loss: 4.1604 - val_accuracy: 0.0393\n",
      "epoch 66\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2127 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0197s vs `on_train_batch_end` time: 0.2966s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1886 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.16037 to 4.15949, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.1886 - accuracy: 0.0352 - val_loss: 4.1595 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1798 - accuracy: 0.0352\n",
      "Epoch 00002: val_loss improved from 4.15949 to 4.15867, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.1798 - accuracy: 0.0352 - val_loss: 4.1587 - val_accuracy: 0.0393\n",
      "epoch 67\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1024 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0141s vs `on_train_batch_end` time: 0.3011s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1315 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.15867 to 4.15780, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.1315 - accuracy: 0.0469 - val_loss: 4.1578 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.7229 - accuracy: 0.0547\n",
      "Epoch 00002: val_loss improved from 4.15780 to 4.15689, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.7229 - accuracy: 0.0547 - val_loss: 4.1569 - val_accuracy: 0.0393\n",
      "epoch 68\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.1481 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0223s vs `on_train_batch_end` time: 0.2948s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5556 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.15689 to 4.15598, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.5556 - accuracy: 0.0469 - val_loss: 4.1560 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5128 - accuracy: 0.0469\n",
      "Epoch 00002: val_loss improved from 4.15598 to 4.15513, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.5128 - accuracy: 0.0469 - val_loss: 4.1551 - val_accuracy: 0.0393\n",
      "epoch 69\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.1110 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0229s vs `on_train_batch_end` time: 0.3188s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1425 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss did not improve from 4.15513\n",
      "8/8 [==============================] - 27s 3s/step - loss: 4.1425 - accuracy: 0.0273 - val_loss: 4.1559 - val_accuracy: 0.0387\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.8560 - accuracy: 0.0273\n",
      "Epoch 00002: val_loss improved from 4.15513 to 4.15340, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.8560 - accuracy: 0.0273 - val_loss: 4.1534 - val_accuracy: 0.0393\n",
      "epoch 70\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.4606 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0152s vs `on_train_batch_end` time: 0.3006s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2684 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.15340 to 4.15264, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.2684 - accuracy: 0.0469 - val_loss: 4.1526 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2692 - accuracy: 0.0469\n",
      "Epoch 00002: val_loss improved from 4.15264 to 4.15192, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.2692 - accuracy: 0.0469 - val_loss: 4.1519 - val_accuracy: 0.0393\n",
      "epoch 71\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.0811 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 0.2952s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1723 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.15192 to 4.15115, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.1723 - accuracy: 0.0352 - val_loss: 4.1512 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2586 - accuracy: 0.0352\n",
      "Epoch 00002: val_loss improved from 4.15115 to 4.15040, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.2586 - accuracy: 0.0352 - val_loss: 4.1504 - val_accuracy: 0.0393\n",
      "epoch 72\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1534 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0193s vs `on_train_batch_end` time: 0.2927s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1361 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.15040 to 4.14965, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.1361 - accuracy: 0.0352 - val_loss: 4.1497 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1344 - accuracy: 0.0352\n",
      "Epoch 00002: val_loss improved from 4.14965 to 4.14880, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 36s 4s/step - loss: 4.1344 - accuracy: 0.0352 - val_loss: 4.1488 - val_accuracy: 0.0393\n",
      "epoch 73\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1643 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0255s vs `on_train_batch_end` time: 0.2882s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1894 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.14880 to 4.14805, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 37s 5s/step - loss: 4.1894 - accuracy: 0.0469 - val_loss: 4.1480 - val_accuracy: 0.0447\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1938 - accuracy: 0.0430\n",
      "Epoch 00002: val_loss improved from 4.14805 to 4.14734, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 50s 6s/step - loss: 4.1938 - accuracy: 0.0430 - val_loss: 4.1473 - val_accuracy: 0.0447\n",
      "epoch 74\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1397 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0224s vs `on_train_batch_end` time: 0.2902s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1417 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.14734 to 4.14663, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 41s 5s/step - loss: 4.1417 - accuracy: 0.0430 - val_loss: 4.1466 - val_accuracy: 0.0447\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.2524 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.14663 to 4.14586, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.2524 - accuracy: 0.0391 - val_loss: 4.1459 - val_accuracy: 0.0447\n",
      "epoch 75\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1435 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0175s vs `on_train_batch_end` time: 0.2899s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1564 - accuracy: 0.0234\n",
      "Epoch 00001: val_loss improved from 4.14586 to 4.14513, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.1564 - accuracy: 0.0234 - val_loss: 4.1451 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1441 - accuracy: 0.0781\n",
      "Epoch 00002: val_loss improved from 4.14513 to 4.14443, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.1441 - accuracy: 0.0781 - val_loss: 4.1444 - val_accuracy: 0.0393\n",
      "epoch 76\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.0922 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0137s vs `on_train_batch_end` time: 0.2921s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1462 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from 4.14443 to 4.14373, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.1462 - accuracy: 0.0273 - val_loss: 4.1437 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.4752 - accuracy: 0.0273\n",
      "Epoch 00002: val_loss improved from 4.14373 to 4.14305, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.4752 - accuracy: 0.0273 - val_loss: 4.1430 - val_accuracy: 0.0393\n",
      "epoch 77\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.0884 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0175s vs `on_train_batch_end` time: 0.2965s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1146 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.14305 to 4.14234, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.1146 - accuracy: 0.0391 - val_loss: 4.1423 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1130 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.14234 to 4.14165, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.1130 - accuracy: 0.0391 - val_loss: 4.1417 - val_accuracy: 0.0393\n",
      "epoch 78\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1205 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0157s vs `on_train_batch_end` time: 0.2905s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1374 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.14165 to 4.14096, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.1374 - accuracy: 0.0312 - val_loss: 4.1410 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1929 - accuracy: 0.0312\n",
      "Epoch 00002: val_loss improved from 4.14096 to 4.14031, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.1929 - accuracy: 0.0312 - val_loss: 4.1403 - val_accuracy: 0.0393\n",
      "epoch 79\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1893 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0191s vs `on_train_batch_end` time: 0.2953s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1092 - accuracy: 0.0234\n",
      "Epoch 00001: val_loss improved from 4.14031 to 4.13963, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.1092 - accuracy: 0.0234 - val_loss: 4.1396 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1111 - accuracy: 0.0234\n",
      "Epoch 00002: val_loss improved from 4.13963 to 4.13882, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.1111 - accuracy: 0.0234 - val_loss: 4.1388 - val_accuracy: 0.0393\n",
      "epoch 80\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.1102 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0145s vs `on_train_batch_end` time: 0.3407s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1472 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.13882 to 4.13809, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.1472 - accuracy: 0.0391 - val_loss: 4.1381 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1086 - accuracy: 0.0391\n",
      "Epoch 00002: val_loss improved from 4.13809 to 4.13744, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.1086 - accuracy: 0.0391 - val_loss: 4.1374 - val_accuracy: 0.0393\n",
      "epoch 81\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.0549 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0196s vs `on_train_batch_end` time: 0.2952s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1240 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from 4.13744 to 4.13680, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 69s 9s/step - loss: 4.1240 - accuracy: 0.0273 - val_loss: 4.1368 - val_accuracy: 0.0393\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1224 - accuracy: 0.0273\n",
      "Epoch 00002: val_loss improved from 4.13680 to 4.13616, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 59s 7s/step - loss: 4.1224 - accuracy: 0.0273 - val_loss: 4.1362 - val_accuracy: 0.0393\n",
      "epoch 82\n",
      "Epoch 1/2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.1491 - accuracy: 0.0312    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0178s vs `on_train_batch_end` time: 0.2844s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.1565 - accuracy: 0.0273"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-1248ff6806c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mix_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     score = age_model.fit(train_x[ix_train], train_y[ix_train],\n\u001b[0m\u001b[1;32m     20\u001b[0m                          \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                          callbacks=[checkpointer])\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1121\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1123\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1124\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "# Model checkpoint to make model save if improvement is there in accuracy\n",
    "# Early stopping if required accuracy is reached - it wont go till end epoch\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# 101 classes so categorical cross entropy - but have to read once again\n",
    "age_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='age_model.hdf5',\n",
    "                              monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                              mode='auto')\n",
    "scores=[]\n",
    "epochs = 250; batch_size=256\n",
    "\n",
    "for i in range(epochs):\n",
    "    print('epoch',i)\n",
    "    ix_train = np.random.choice(train_x.shape[0], size=batch_size)\n",
    "    score = age_model.fit(train_x[ix_train], train_y[ix_train],\n",
    "                         epochs=2, validation_data=(test_x, test_y),\n",
    "                         callbacks=[checkpointer])\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
