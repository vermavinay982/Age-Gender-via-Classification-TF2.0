{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING THE PREPROCESSED DATA - CONTAINING IMAGES TOO\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('withpixel_gender.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[17/10000217_1981-05-05_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[12/100012_1948-07-03_2008.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>[92.0, 97.0, 91.0, 89.0, 94.0, 90.0, 91.0, 96....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[16/10002116_1971-05-31_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>[61.0, 30.0, 10.0, 61.0, 30.0, 10.0, 61.0, 30....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[02/10002702_1960-11-09_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>[97.0, 122.0, 178.0, 97.0, 122.0, 178.0, 97.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[41/10003541_1937-09-27_1971.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>[190.0, 189.0, 194.0, 204.0, 203.0, 208.0, 203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62321</th>\n",
       "      <td>[38/9996938_1937-02-15_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>[71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62322</th>\n",
       "      <td>[46/9996946_1943-11-01_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>[54.0, 54.0, 54.0, 44.0, 44.0, 44.0, 28.0, 28....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62323</th>\n",
       "      <td>[49/9996949_1937-04-17_1963.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>[41.0, 41.0, 41.0, 29.0, 29.0, 29.0, 22.0, 22....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62325</th>\n",
       "      <td>[09/9998109_1972-12-27_2013.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>[137.0, 174.0, 94.0, 137.0, 174.0, 94.0, 137.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62327</th>\n",
       "      <td>[80/999980_1954-06-11_2008.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>[35.0, 36.0, 18.0, 35.0, 36.0, 18.0, 36.0, 37....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39382 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               full_path  gender  age  \\\n",
       "0      [17/10000217_1981-05-05_2009.jpg]     1.0   28   \n",
       "2        [12/100012_1948-07-03_2008.jpg]     1.0   60   \n",
       "4      [16/10002116_1971-05-31_2012.jpg]     0.0   41   \n",
       "5      [02/10002702_1960-11-09_2012.jpg]     0.0   52   \n",
       "6      [41/10003541_1937-09-27_1971.jpg]     1.0   34   \n",
       "...                                  ...     ...  ...   \n",
       "62321   [38/9996938_1937-02-15_1968.jpg]     1.0   31   \n",
       "62322   [46/9996946_1943-11-01_1968.jpg]     1.0   25   \n",
       "62323   [49/9996949_1937-04-17_1963.jpg]     1.0   26   \n",
       "62325   [09/9998109_1972-12-27_2013.jpg]     1.0   41   \n",
       "62327    [80/999980_1954-06-11_2008.jpg]     0.0   54   \n",
       "\n",
       "                                                  pixels  \n",
       "0      [255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255...  \n",
       "2      [92.0, 97.0, 91.0, 89.0, 94.0, 90.0, 91.0, 96....  \n",
       "4      [61.0, 30.0, 10.0, 61.0, 30.0, 10.0, 61.0, 30....  \n",
       "5      [97.0, 122.0, 178.0, 97.0, 122.0, 178.0, 97.0,...  \n",
       "6      [190.0, 189.0, 194.0, 204.0, 203.0, 208.0, 203...  \n",
       "...                                                  ...  \n",
       "62321  [71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71....  \n",
       "62322  [54.0, 54.0, 54.0, 44.0, 44.0, 44.0, 28.0, 28....  \n",
       "62323  [41.0, 41.0, 41.0, 29.0, 29.0, 29.0, 22.0, 22....  \n",
       "62325  [137.0, 174.0, 94.0, 137.0, 174.0, 94.0, 137.0...  \n",
       "62327  [35.0, 36.0, 18.0, 35.0, 36.0, 18.0, 36.0, 37....  \n",
       "\n",
       "[39382 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "full path - the path of image file\n",
    "gender - 0,1 denoting male female\n",
    "age - the category of the person with age group\n",
    "pixels - image encoded as matrix in dataframe\n",
    "\"\"\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done - decided number of features are collected\n"
     ]
    }
   ],
   "source": [
    "classes = 2 # 2 for gender\n",
    "target = df['gender'].values\n",
    "target_classes = keras.utils.to_categorical(target, classes)\n",
    "\n",
    "features = []\n",
    "\n",
    "# limiting the target classes, and featues to limit memory usage\n",
    "# both target and feature must match with the split dataset \n",
    "limit_dataset = 10000\n",
    "\n",
    "target_classes = target_classes[:limit_dataset]\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    features.append(df['pixels'].values[i])\n",
    "    if len(features)>=limit_dataset:\n",
    "        print('Done - decided number of features are collected')\n",
    "        break\n",
    "\n",
    "# convering the list into numpy - that can be used for batch training\n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "7000 3000\n"
     ]
    }
   ],
   "source": [
    "# managing splits in dataset for training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, target_classes, test_size=0.30)\n",
    "\n",
    "print(len(features))\n",
    "print(len(target_classes))\n",
    "print(len(train_x),len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since memory consumption is very high -we need to delete the df to get it back\n",
    "# del df\n",
    "# del features # 20 gb ram freeedddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the base VGG Face Model\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "\n",
    "# vgg-face model \n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1), input_shape=(224,224,3)))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128,(3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7,7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1,1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained vgg weights availble on drive\n",
    "# you can find it here: https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "\n",
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the last layers of network to get 100 predictions for classes\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# lock the layer weights for early layers \n",
    "# - they could already detect some patterns\n",
    "# fitting the network from scratch might cause to lose this info\n",
    "# freeze all layers except last 3 conv layers - 2622 units\n",
    "# just 101 units for age prediction task\n",
    "# then add custom layer for 101 layers\n",
    "\n",
    "# to not lose the training done before in pretrained weights\n",
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "base_model_output = Sequential()\n",
    "base_model_output = Convolution2D(2, (1, 1), name='predictions')(model.layers[-4].output)\n",
    "base_model_output = Flatten()(base_model_output)\n",
    "base_model_output = Activation('softmax')(base_model_output)\n",
    " \n",
    "gender_model = Model(inputs=model.input, outputs=base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_13_input (Inp [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPaddi (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPaddi (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPaddi (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPaddi (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPaddi (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPaddi (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPaddi (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPaddi (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPaddi (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "predictions (Conv2D)         (None, 1, 1, 2)           8194      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 119,554,050\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gender_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-67e866c9127d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mix_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     score = gender_model.fit(train_x[ix_train], train_y[ix_train],\n\u001b[0m\u001b[1;32m     14\u001b[0m         epochs=1, validation_data=(test_x, test_y), callbacks=[checkpointer])\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1029\u001b[0m     \u001b[0;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1032\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2567\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2569\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2570\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2571\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "scores = []\n",
    "epochs = 250; batch_size = 256\n",
    "\n",
    "# 101 classes so categorical cross entropy - but have to read once again\n",
    "gender_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='gender_model.hdf5',monitor='val_loss',\n",
    "                verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"epoch \",i)\n",
    " \n",
    "    ix_train = np.random.choice(train_x.shape[0], size=batch_size)\n",
    " \n",
    "    score = gender_model.fit(train_x[ix_train], train_y[ix_train],\n",
    "        epochs=1, validation_data=(test_x, test_y), callbacks=[checkpointer])\n",
    "\n",
    "scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
