{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas\n",
    "# ! pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING THE PREPROCESSED DATA - CONTAINING IMAGES TOO\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('withpixel_gender.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[17/10000217_1981-05-05_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[12/100012_1948-07-03_2008.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>[92.0, 97.0, 91.0, 89.0, 94.0, 90.0, 91.0, 96....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[16/10002116_1971-05-31_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>[61.0, 30.0, 10.0, 61.0, 30.0, 10.0, 61.0, 30....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[02/10002702_1960-11-09_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>[97.0, 122.0, 178.0, 97.0, 122.0, 178.0, 97.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[41/10003541_1937-09-27_1971.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>[190.0, 189.0, 194.0, 204.0, 203.0, 208.0, 203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62321</th>\n",
       "      <td>[38/9996938_1937-02-15_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>[71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62322</th>\n",
       "      <td>[46/9996946_1943-11-01_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>[54.0, 54.0, 54.0, 44.0, 44.0, 44.0, 28.0, 28....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62323</th>\n",
       "      <td>[49/9996949_1937-04-17_1963.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>[41.0, 41.0, 41.0, 29.0, 29.0, 29.0, 22.0, 22....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62325</th>\n",
       "      <td>[09/9998109_1972-12-27_2013.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>[137.0, 174.0, 94.0, 137.0, 174.0, 94.0, 137.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62327</th>\n",
       "      <td>[80/999980_1954-06-11_2008.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>[35.0, 36.0, 18.0, 35.0, 36.0, 18.0, 36.0, 37....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39382 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               full_path  gender  age  \\\n",
       "0      [17/10000217_1981-05-05_2009.jpg]     1.0   28   \n",
       "2        [12/100012_1948-07-03_2008.jpg]     1.0   60   \n",
       "4      [16/10002116_1971-05-31_2012.jpg]     0.0   41   \n",
       "5      [02/10002702_1960-11-09_2012.jpg]     0.0   52   \n",
       "6      [41/10003541_1937-09-27_1971.jpg]     1.0   34   \n",
       "...                                  ...     ...  ...   \n",
       "62321   [38/9996938_1937-02-15_1968.jpg]     1.0   31   \n",
       "62322   [46/9996946_1943-11-01_1968.jpg]     1.0   25   \n",
       "62323   [49/9996949_1937-04-17_1963.jpg]     1.0   26   \n",
       "62325   [09/9998109_1972-12-27_2013.jpg]     1.0   41   \n",
       "62327    [80/999980_1954-06-11_2008.jpg]     0.0   54   \n",
       "\n",
       "                                                  pixels  \n",
       "0      [255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255...  \n",
       "2      [92.0, 97.0, 91.0, 89.0, 94.0, 90.0, 91.0, 96....  \n",
       "4      [61.0, 30.0, 10.0, 61.0, 30.0, 10.0, 61.0, 30....  \n",
       "5      [97.0, 122.0, 178.0, 97.0, 122.0, 178.0, 97.0,...  \n",
       "6      [190.0, 189.0, 194.0, 204.0, 203.0, 208.0, 203...  \n",
       "...                                                  ...  \n",
       "62321  [71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71....  \n",
       "62322  [54.0, 54.0, 54.0, 44.0, 44.0, 44.0, 28.0, 28....  \n",
       "62323  [41.0, 41.0, 41.0, 29.0, 29.0, 29.0, 22.0, 22....  \n",
       "62325  [137.0, 174.0, 94.0, 137.0, 174.0, 94.0, 137.0...  \n",
       "62327  [35.0, 36.0, 18.0, 35.0, 36.0, 18.0, 36.0, 37....  \n",
       "\n",
       "[39382 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "full path - the path of image file\n",
    "gender - 0,1 denoting male female\n",
    "age - the category of the person with age group\n",
    "pixels - image encoded as matrix in dataframe\n",
    "\"\"\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done - given number of features collected\n"
     ]
    }
   ],
   "source": [
    "classes = 101 # 0 to 100\n",
    "target = df['age'].values\n",
    "target_classes = keras.utils.to_categorical(target, classes)\n",
    "\n",
    "features = []\n",
    "\n",
    "# limiting the target classes, and featues to limit memory usage\n",
    "# both target and feature must match with the split dataset \n",
    "limit_dataset = 10000\n",
    "\n",
    "target_classes = target_classes[:limit_dataset]\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    features.append(df['pixels'].values[i])\n",
    "    if len(features)=>limit_dataset:\n",
    "        print('Done - decided number of features are collected')\n",
    "        break\n",
    "\n",
    "# convering the list into numpy - that can be used for batch training\n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target = target[:10000]\n",
    "# len(target)\n",
    "# target_classes=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# managing splits in dataset for training and evaluation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, target_classes, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(features))\n",
    "print(len(target_classes))\n",
    "print(len(train_x),len(text__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since memory consumption is very high -we need to delete the df to get it back\n",
    "# del df\n",
    "# del features # 20 gb ram freeedddd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('image_features.pickle', 'wb') as handle:\n",
    "#     pickle.dump(features, handle)\n",
    "    \n",
    "# target_gender = df['gender'].values\n",
    "\n",
    "# with open('gender_target.pickle', 'wb') as handle:\n",
    "#     pickle.dump(target_gender, handle)\n",
    "    \n",
    "# with open('age_target.pickle', 'wb') as handle:\n",
    "#     pickle.dump(target, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "\n",
    "# vgg-face model \n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1), input_shape=(224,224,3)))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128,(3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7,7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1,1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! git add .\n",
    "# ! git commit -am \"vgg defined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d (ZeroPadding2 (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 1, 1, 2622)        10742334  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2622)              0         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2622)              0         \n",
      "=================================================================\n",
      "Total params: 145,002,878\n",
      "Trainable params: 145,002,878\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model\n",
    "\n",
    "# lock the layer weights for early layers \n",
    "# - they could already detect some patterns\n",
    "# fitting the network from scratch might cause to lose this info\n",
    "# freeze all layers except last 3 conv layers - 2622 units\n",
    "# just 101 units for age prediction task\n",
    "# then add custom layer for 101 layers\n",
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "base_model_output = Sequential()\n",
    "base_model_output = Convolution2D(101, (1,1), name='predictions')(model.layers[-4].output)\n",
    "base_model_output = Flatten()(base_model_output)\n",
    "base_model_output = Activation('softmax')(base_model_output)\n",
    "\n",
    "age_model = Model(inputs=model.input, outputs=base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_input (InputL [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPaddin (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPaddin (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPaddin (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPaddin (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPaddin (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "predictions (Conv2D)         (None, 1, 1, 101)         413797    \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 101)               0         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 101)               0         \n",
      "=================================================================\n",
      "Total params: 134,674,341\n",
      "Trainable params: 119,959,653\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "age_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "8/8 [==============================] - ETA: 0s - loss: 14.5632 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from inf to 5.37407, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 41s 5s/step - loss: 14.5632 - accuracy: 0.0273 - val_loss: 5.3741 - val_accuracy: 0.0163\n",
      "epoch 1\n",
      "8/8 [==============================] - ETA: 0s - loss: 7.5237 - accuracy: 0.0078    \n",
      "Epoch 00001: val_loss improved from 5.37407 to 4.85318, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 7.5237 - accuracy: 0.0078 - val_loss: 4.8532 - val_accuracy: 0.0263\n",
      "epoch 2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 6.1669 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0216s vs `on_train_batch_end` time: 0.2741s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.3069 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.85318 to 4.60606, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 5.3069 - accuracy: 0.0391 - val_loss: 4.6061 - val_accuracy: 0.0307\n",
      "epoch 3\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.6098 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0168s vs `on_train_batch_end` time: 0.2819s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.9387 - accuracy: 0.0234\n",
      "Epoch 00001: val_loss improved from 4.60606 to 4.60258, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.9387 - accuracy: 0.0234 - val_loss: 4.6026 - val_accuracy: 0.0313\n",
      "epoch 4\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.7715 - accuracy: 0.0781WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0212s vs `on_train_batch_end` time: 0.2819s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.4099 - accuracy: 0.0508\n",
      "Epoch 00001: val_loss did not improve from 4.60258\n",
      "8/8 [==============================] - 26s 3s/step - loss: 5.4099 - accuracy: 0.0508 - val_loss: 4.6396 - val_accuracy: 0.0160\n",
      "epoch 5\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.8079 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0250s vs `on_train_batch_end` time: 0.2829s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.8492 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from 4.60258 to 4.59637, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.8492 - accuracy: 0.0273 - val_loss: 4.5964 - val_accuracy: 0.0317\n",
      "epoch 6\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.9169 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 0.3181s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.9030 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.59637 to 4.59045, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.9030 - accuracy: 0.0312 - val_loss: 4.5905 - val_accuracy: 0.0307\n",
      "epoch 7\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 5.3076 - accuracy: 0.0625    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0221s vs `on_train_batch_end` time: 0.2851s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.9553 - accuracy: 0.0234\n",
      "Epoch 00001: val_loss improved from 4.59045 to 4.58649, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.9553 - accuracy: 0.0234 - val_loss: 4.5865 - val_accuracy: 0.0307\n",
      "epoch 8\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.5835 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 0.2936s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.8377 - accuracy: 0.0508\n",
      "Epoch 00001: val_loss improved from 4.58649 to 4.58252, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.8377 - accuracy: 0.0508 - val_loss: 4.5825 - val_accuracy: 0.0447\n",
      "epoch 9\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.7480 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0183s vs `on_train_batch_end` time: 0.3046s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.6646 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.58252 to 4.57857, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 4.6646 - accuracy: 0.0469 - val_loss: 4.5786 - val_accuracy: 0.0447\n",
      "epoch 10\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.9812 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0210s vs `on_train_batch_end` time: 0.2860s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.7978 - accuracy: 0.0391\n",
      "Epoch 00001: val_loss improved from 4.57857 to 4.57462, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.7978 - accuracy: 0.0391 - val_loss: 4.5746 - val_accuracy: 0.0453\n",
      "epoch 11\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.6835 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0140s vs `on_train_batch_end` time: 0.2929s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.0445 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from 4.57462 to 4.57072, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 5.0445 - accuracy: 0.0273 - val_loss: 4.5707 - val_accuracy: 0.0447\n",
      "epoch 12\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.5917 - accuracy: 0.0312    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0190s vs `on_train_batch_end` time: 0.2859s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.6505 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.57072 to 4.56672, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 4.6505 - accuracy: 0.0312 - val_loss: 4.5667 - val_accuracy: 0.0447\n",
      "epoch 13\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.8002 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0197s vs `on_train_batch_end` time: 0.2930s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.2794 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.56672 to 4.56288, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 5.2794 - accuracy: 0.0352 - val_loss: 4.5629 - val_accuracy: 0.0393\n",
      "epoch 14\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.5858 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0145s vs `on_train_batch_end` time: 0.2968s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5720 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.56288 to 4.55897, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.5720 - accuracy: 0.0469 - val_loss: 4.5590 - val_accuracy: 0.0393\n",
      "epoch 15\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 5.0824 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0271s vs `on_train_batch_end` time: 0.2853s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.9243 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss improved from 4.55897 to 4.55521, saving model to age_model.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 34s 4s/step - loss: 4.9243 - accuracy: 0.0312 - val_loss: 4.5552 - val_accuracy: 0.0393\n",
      "epoch 16\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.5681 - accuracy: 0.0312    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0141s vs `on_train_batch_end` time: 0.2939s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.6898 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.55521 to 4.55153, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.6898 - accuracy: 0.0430 - val_loss: 4.5515 - val_accuracy: 0.0393\n",
      "epoch 17\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.5471 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0178s vs `on_train_batch_end` time: 0.2944s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.7310 - accuracy: 0.0469\n",
      "Epoch 00001: val_loss improved from 4.55153 to 4.54785, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.7310 - accuracy: 0.0469 - val_loss: 4.5478 - val_accuracy: 0.0397\n",
      "epoch 18\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.6026 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0220s vs `on_train_batch_end` time: 0.2912s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5779 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss did not improve from 4.54785\n",
      "8/8 [==============================] - 27s 3s/step - loss: 4.5779 - accuracy: 0.0273 - val_loss: 5.1426 - val_accuracy: 0.0060\n",
      "epoch 19\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 5.2360 - accuracy: 0.0312WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0196s vs `on_train_batch_end` time: 0.2930s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.8824 - accuracy: 0.0273\n",
      "Epoch 00001: val_loss improved from 4.54785 to 4.54026, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.8824 - accuracy: 0.0273 - val_loss: 4.5403 - val_accuracy: 0.0393\n",
      "epoch 20\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.5966 - accuracy: 0.0312    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0207s vs `on_train_batch_end` time: 0.2932s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5547 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss did not improve from 4.54026\n",
      "8/8 [==============================] - 27s 3s/step - loss: 4.5547 - accuracy: 0.0352 - val_loss: 4.5530 - val_accuracy: 0.0437\n",
      "epoch 21\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.8902 - accuracy: 0.0156WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0200s vs `on_train_batch_end` time: 0.2933s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.7638 - accuracy: 0.0234\n",
      "Epoch 00001: val_loss improved from 4.54026 to 4.53324, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.7638 - accuracy: 0.0234 - val_loss: 4.5332 - val_accuracy: 0.0393\n",
      "epoch 22\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.5820 - accuracy: 0.0938WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0223s vs `on_train_batch_end` time: 0.2959s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.3772 - accuracy: 0.0625\n",
      "Epoch 00001: val_loss improved from 4.53324 to 4.52963, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 5.3772 - accuracy: 0.0625 - val_loss: 4.5296 - val_accuracy: 0.0393\n",
      "epoch 23\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.7630 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0163s vs `on_train_batch_end` time: 0.2915s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.6091 - accuracy: 0.0430\n",
      "Epoch 00001: val_loss improved from 4.52963 to 4.52615, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 4.6091 - accuracy: 0.0430 - val_loss: 4.5261 - val_accuracy: 0.0393\n",
      "epoch 24\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.5561 - accuracy: 0.0469WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0168s vs `on_train_batch_end` time: 0.2930s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5823 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.52615 to 4.52249, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 32s 4s/step - loss: 4.5823 - accuracy: 0.0352 - val_loss: 4.5225 - val_accuracy: 0.0393\n",
      "epoch 25\n",
      "2/8 [======>.......................] - ETA: 2s - loss: 4.5687 - accuracy: 0.0625    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0232s vs `on_train_batch_end` time: 0.2939s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.6444 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss did not improve from 4.52249\n",
      "8/8 [==============================] - 26s 3s/step - loss: 4.6444 - accuracy: 0.0352 - val_loss: 5.4528 - val_accuracy: 0.0030\n",
      "epoch 26\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 5.2646 - accuracy: 0.0312    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0201s vs `on_train_batch_end` time: 0.3005s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.7240 - accuracy: 0.0312\n",
      "Epoch 00001: val_loss did not improve from 4.52249\n",
      "8/8 [==============================] - 27s 3s/step - loss: 4.7240 - accuracy: 0.0312 - val_loss: 4.6006 - val_accuracy: 0.0353\n",
      "epoch 27\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.9740 - accuracy: 0.0156    WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0184s vs `on_train_batch_end` time: 0.2984s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.9696 - accuracy: 0.0352\n",
      "Epoch 00001: val_loss improved from 4.52249 to 4.51164, saving model to age_model.hdf5\n",
      "8/8 [==============================] - 34s 4s/step - loss: 4.9696 - accuracy: 0.0352 - val_loss: 4.5116 - val_accuracy: 0.0393\n",
      "epoch 28\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.7324 - accuracy: 0.0625WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0221s vs `on_train_batch_end` time: 0.2905s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.5712 - accuracy: 0.0508"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "age_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='age_model.hdf5',\n",
    "                              monitor='val_loss', verbose=1, save_best_only=True,\n",
    "                              mode='auto')\n",
    "scores=[]\n",
    "epochs = 250; batch_size=256\n",
    "\n",
    "for i in range(epochs):\n",
    "    print('epoch',i)\n",
    "    ix_train = np.random.choice(train_x.shape[0], size=batch_size)\n",
    "    score = age_model.fit(train_x[ix_train], train_y[ix_train],\n",
    "                         epochs=1, validation_data=(test_x, test_y),\n",
    "                         callbacks=[checkpointer])\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
