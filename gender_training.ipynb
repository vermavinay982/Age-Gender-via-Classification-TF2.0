{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "  tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING THE PREPROCESSED DATA - CONTAINING IMAGES TOO\n",
    "import pandas as pd\n",
    "df = pd.read_pickle('withpixel_gender.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_path</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[17/10000217_1981-05-05_2009.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>[255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[12/100012_1948-07-03_2008.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60</td>\n",
       "      <td>[92.0, 97.0, 91.0, 89.0, 94.0, 90.0, 91.0, 96....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[16/10002116_1971-05-31_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "      <td>[61.0, 30.0, 10.0, 61.0, 30.0, 10.0, 61.0, 30....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[02/10002702_1960-11-09_2012.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "      <td>[97.0, 122.0, 178.0, 97.0, 122.0, 178.0, 97.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[41/10003541_1937-09-27_1971.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>34</td>\n",
       "      <td>[190.0, 189.0, 194.0, 204.0, 203.0, 208.0, 203...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62321</th>\n",
       "      <td>[38/9996938_1937-02-15_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>[71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62322</th>\n",
       "      <td>[46/9996946_1943-11-01_1968.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>[54.0, 54.0, 54.0, 44.0, 44.0, 44.0, 28.0, 28....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62323</th>\n",
       "      <td>[49/9996949_1937-04-17_1963.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>[41.0, 41.0, 41.0, 29.0, 29.0, 29.0, 22.0, 22....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62325</th>\n",
       "      <td>[09/9998109_1972-12-27_2013.jpg]</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41</td>\n",
       "      <td>[137.0, 174.0, 94.0, 137.0, 174.0, 94.0, 137.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62327</th>\n",
       "      <td>[80/999980_1954-06-11_2008.jpg]</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54</td>\n",
       "      <td>[35.0, 36.0, 18.0, 35.0, 36.0, 18.0, 36.0, 37....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>39382 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               full_path  gender  age  \\\n",
       "0      [17/10000217_1981-05-05_2009.jpg]     1.0   28   \n",
       "2        [12/100012_1948-07-03_2008.jpg]     1.0   60   \n",
       "4      [16/10002116_1971-05-31_2012.jpg]     0.0   41   \n",
       "5      [02/10002702_1960-11-09_2012.jpg]     0.0   52   \n",
       "6      [41/10003541_1937-09-27_1971.jpg]     1.0   34   \n",
       "...                                  ...     ...  ...   \n",
       "62321   [38/9996938_1937-02-15_1968.jpg]     1.0   31   \n",
       "62322   [46/9996946_1943-11-01_1968.jpg]     1.0   25   \n",
       "62323   [49/9996949_1937-04-17_1963.jpg]     1.0   26   \n",
       "62325   [09/9998109_1972-12-27_2013.jpg]     1.0   41   \n",
       "62327    [80/999980_1954-06-11_2008.jpg]     0.0   54   \n",
       "\n",
       "                                                  pixels  \n",
       "0      [255.0, 255.0, 255.0, 255.0, 255.0, 255.0, 255...  \n",
       "2      [92.0, 97.0, 91.0, 89.0, 94.0, 90.0, 91.0, 96....  \n",
       "4      [61.0, 30.0, 10.0, 61.0, 30.0, 10.0, 61.0, 30....  \n",
       "5      [97.0, 122.0, 178.0, 97.0, 122.0, 178.0, 97.0,...  \n",
       "6      [190.0, 189.0, 194.0, 204.0, 203.0, 208.0, 203...  \n",
       "...                                                  ...  \n",
       "62321  [71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71.0, 71....  \n",
       "62322  [54.0, 54.0, 54.0, 44.0, 44.0, 44.0, 28.0, 28....  \n",
       "62323  [41.0, 41.0, 41.0, 29.0, 29.0, 29.0, 22.0, 22....  \n",
       "62325  [137.0, 174.0, 94.0, 137.0, 174.0, 94.0, 137.0...  \n",
       "62327  [35.0, 36.0, 18.0, 35.0, 36.0, 18.0, 36.0, 37....  \n",
       "\n",
       "[39382 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "full path - the path of image file\n",
    "gender - 0,1 denoting male female\n",
    "age - the category of the person with age group\n",
    "pixels - image encoded as matrix in dataframe\n",
    "\"\"\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done - decided number of features are collected\n"
     ]
    }
   ],
   "source": [
    "classes = 2 # 2 for gender\n",
    "target = df['gender'].values\n",
    "target_classes = keras.utils.to_categorical(target, classes)\n",
    "\n",
    "features = []\n",
    "\n",
    "# limiting the target classes, and featues to limit memory usage\n",
    "# both target and feature must match with the split dataset \n",
    "limit_dataset = 10000\n",
    "\n",
    "target_classes = target_classes[:limit_dataset]\n",
    "\n",
    "for i in range(0, df.shape[0]):\n",
    "    features.append(df['pixels'].values[i])\n",
    "    if len(features)>=limit_dataset:\n",
    "        print('Done - decided number of features are collected')\n",
    "        break\n",
    "\n",
    "# convering the list into numpy - that can be used for batch training\n",
    "features = np.array(features)\n",
    "features = features.reshape(features.shape[0], 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "7000 3000\n"
     ]
    }
   ],
   "source": [
    "# managing splits in dataset for training and evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_x, test_x, train_y, test_y = train_test_split(features, target_classes, test_size=0.30)\n",
    "\n",
    "print(len(features))\n",
    "print(len(target_classes))\n",
    "print(len(train_x),len(test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since memory consumption is very high -we need to delete the df to get it back\n",
    "# del df\n",
    "# del features # 20 gb ram freeedddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the base VGG Face Model\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import ZeroPadding2D\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "\n",
    "# vgg-face model \n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1), input_shape=(224,224,3)))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128,(3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128,(3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Convolution2D(4096, (7,7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1,1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained vgg weights availble on drive\n",
    "# you can find it here: https://drive.google.com/file/d/1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo/view?usp=sharing\n",
    "\n",
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the last layers of network to get 100 predictions for classes\n",
    "\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "# lock the layer weights for early layers \n",
    "# - they could already detect some patterns\n",
    "# fitting the network from scratch might cause to lose this info\n",
    "# freeze all layers except last 3 conv layers - 2622 units\n",
    "# just 101 units for age prediction task\n",
    "# then add custom layer for 101 layers\n",
    "\n",
    "# to not lose the training done before in pretrained weights\n",
    "for layer in model.layers[:-7]:\n",
    "    layer.trainable = False\n",
    "\n",
    "base_model_output = Sequential()\n",
    "base_model_output = Convolution2D(2, (1, 1), name='predictions')(model.layers[-4].output)\n",
    "base_model_output = Flatten()(base_model_output)\n",
    "base_model_output = Activation('softmax')(base_model_output)\n",
    " \n",
    "gender_model = Model(inputs=model.input, outputs=base_model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_13_input (Inp [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPaddi (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPaddi (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPaddi (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPaddi (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPaddi (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPaddi (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPaddi (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPaddi (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPaddi (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPaddi (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 1, 1, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 1, 1, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "predictions (Conv2D)         (None, 1, 1, 2)           8194      \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 119,554,050\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gender_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "8/8 [==============================] - ETA: 0s - loss: 8.1207 - accuracy: 0.6719\n",
      "Epoch 00001: val_loss improved from inf to 26.48033, saving model to gender_model.hdf5\n",
      "8/8 [==============================] - 43s 5s/step - loss: 8.1207 - accuracy: 0.6719 - val_loss: 26.4803 - val_accuracy: 0.2483\n",
      "epoch  1\n",
      "8/8 [==============================] - ETA: 0s - loss: 11.0508 - accuracy: 0.7344\n",
      "Epoch 00001: val_loss improved from 26.48033 to 3.32140, saving model to gender_model.hdf5\n",
      "8/8 [==============================] - 30s 4s/step - loss: 11.0508 - accuracy: 0.7344 - val_loss: 3.3214 - val_accuracy: 0.8243\n",
      "epoch  2\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.6277 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0147s vs `on_train_batch_end` time: 0.2802s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.7074 - accuracy: 0.8789\n",
      "Epoch 00001: val_loss did not improve from 3.32140\n",
      "8/8 [==============================] - 25s 3s/step - loss: 4.7074 - accuracy: 0.8789 - val_loss: 5.7908 - val_accuracy: 0.9033\n",
      "epoch  3\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 11.1755 - accuracy: 0.8281WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0195s vs `on_train_batch_end` time: 0.2820s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 11.5372 - accuracy: 0.8594\n",
      "Epoch 00001: val_loss improved from 3.32140 to 2.95850, saving model to gender_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 11.5372 - accuracy: 0.8594 - val_loss: 2.9585 - val_accuracy: 0.9347\n",
      "epoch  4\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 10.0750 - accuracy: 0.8281WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0205s vs `on_train_batch_end` time: 0.2787s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 10.7124 - accuracy: 0.8711\n",
      "Epoch 00001: val_loss improved from 2.95850 to 2.61134, saving model to gender_model.hdf5\n",
      "8/8 [==============================] - 33s 4s/step - loss: 10.7124 - accuracy: 0.8711 - val_loss: 2.6113 - val_accuracy: 0.9447\n",
      "epoch  5\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.8946 - accuracy: 0.9219WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0163s vs `on_train_batch_end` time: 0.2832s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 7.9784 - accuracy: 0.9023\n",
      "Epoch 00001: val_loss did not improve from 2.61134\n",
      "8/8 [==============================] - 25s 3s/step - loss: 7.9784 - accuracy: 0.9023 - val_loss: 3.3992 - val_accuracy: 0.9297\n",
      "epoch  6\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 1.5947 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0170s vs `on_train_batch_end` time: 0.2907s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.5083 - accuracy: 0.9297\n",
      "Epoch 00001: val_loss did not improve from 2.61134\n",
      "8/8 [==============================] - 25s 3s/step - loss: 2.5083 - accuracy: 0.9297 - val_loss: 4.0634 - val_accuracy: 0.9383\n",
      "epoch  7\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 5.6754 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0151s vs `on_train_batch_end` time: 0.2908s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 7.6160 - accuracy: 0.8945\n",
      "Epoch 00001: val_loss did not improve from 2.61134\n",
      "8/8 [==============================] - 25s 3s/step - loss: 7.6160 - accuracy: 0.8945 - val_loss: 9.7490 - val_accuracy: 0.8997\n",
      "epoch  8\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 10.0923 - accuracy: 0.8906WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0145s vs `on_train_batch_end` time: 0.2907s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 7.9370 - accuracy: 0.8984\n",
      "Epoch 00001: val_loss did not improve from 2.61134\n",
      "8/8 [==============================] - 26s 3s/step - loss: 7.9370 - accuracy: 0.8984 - val_loss: 4.1261 - val_accuracy: 0.9383\n",
      "epoch  9\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 5.6432 - accuracy: 0.9219WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0149s vs `on_train_batch_end` time: 0.2944s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 3.8184 - accuracy: 0.9375\n",
      "Epoch 00001: val_loss improved from 2.61134 to 2.01493, saving model to gender_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 3.8184 - accuracy: 0.9375 - val_loss: 2.0149 - val_accuracy: 0.9503\n",
      "epoch  10\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 2.6637 - accuracy: 0.9062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0228s vs `on_train_batch_end` time: 0.2920s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.4281 - accuracy: 0.9219\n",
      "Epoch 00001: val_loss did not improve from 2.01493\n",
      "8/8 [==============================] - 26s 3s/step - loss: 2.4281 - accuracy: 0.9219 - val_loss: 4.6351 - val_accuracy: 0.8760\n",
      "epoch  11\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 2.1668 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0184s vs `on_train_batch_end` time: 0.2974s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.5449 - accuracy: 0.9453\n",
      "Epoch 00001: val_loss did not improve from 2.01493\n",
      "8/8 [==============================] - 26s 3s/step - loss: 5.5449 - accuracy: 0.9453 - val_loss: 2.9722 - val_accuracy: 0.9463\n",
      "epoch  12\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 5.9378 - accuracy: 0.9531WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0156s vs `on_train_batch_end` time: 0.2926s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 6.8673 - accuracy: 0.9375\n",
      "Epoch 00001: val_loss did not improve from 2.01493\n",
      "8/8 [==============================] - 26s 3s/step - loss: 6.8673 - accuracy: 0.9375 - val_loss: 11.8449 - val_accuracy: 0.8720\n",
      "epoch  13\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 8.4178 - accuracy: 0.9062 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0124s vs `on_train_batch_end` time: 0.3042s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.0105 - accuracy: 0.9141\n",
      "Epoch 00001: val_loss did not improve from 2.01493\n",
      "8/8 [==============================] - 27s 3s/step - loss: 5.0105 - accuracy: 0.9141 - val_loss: 3.8587 - val_accuracy: 0.9443\n",
      "epoch  14\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 7.8667 - accuracy: 0.9062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0126s vs `on_train_batch_end` time: 0.3052s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 7.7910 - accuracy: 0.9102\n",
      "Epoch 00001: val_loss improved from 2.01493 to 1.92995, saving model to gender_model.hdf5\n",
      "8/8 [==============================] - 31s 4s/step - loss: 7.7910 - accuracy: 0.9102 - val_loss: 1.9299 - val_accuracy: 0.9427\n",
      "epoch  15\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 1.1145 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0189s vs `on_train_batch_end` time: 0.2970s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 3.1459 - accuracy: 0.9219\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 26s 3s/step - loss: 3.1459 - accuracy: 0.9219 - val_loss: 4.6384 - val_accuracy: 0.9293\n",
      "epoch  16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/8 [======>.......................] - ETA: 1s - loss: 14.0974 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0288s vs `on_train_batch_end` time: 0.2905s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 6.8028 - accuracy: 0.9023\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 26s 3s/step - loss: 6.8028 - accuracy: 0.9023 - val_loss: 3.0576 - val_accuracy: 0.9377\n",
      "epoch  17\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 4.2930 - accuracy: 0.9844WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0183s vs `on_train_batch_end` time: 0.2993s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 3.6582 - accuracy: 0.9219\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 27s 3s/step - loss: 3.6582 - accuracy: 0.9219 - val_loss: 7.2471 - val_accuracy: 0.8853\n",
      "epoch  18\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 9.5100 - accuracy: 0.8594 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0238s vs `on_train_batch_end` time: 0.3295s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.8092 - accuracy: 0.9180\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 26s 3s/step - loss: 5.8092 - accuracy: 0.9180 - val_loss: 3.8051 - val_accuracy: 0.9463\n",
      "epoch  19\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 2.6835 - accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0129s vs `on_train_batch_end` time: 0.2987s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 2.9251 - accuracy: 0.9648\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 27s 3s/step - loss: 2.9251 - accuracy: 0.9648 - val_loss: 4.5073 - val_accuracy: 0.9207\n",
      "epoch  20\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 20.0794 - accuracy: 0.9062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0145s vs `on_train_batch_end` time: 0.3064s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 6.4167 - accuracy: 0.9297\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 27s 3s/step - loss: 6.4167 - accuracy: 0.9297 - val_loss: 2.6410 - val_accuracy: 0.9297\n",
      "epoch  21\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 2.2138 - accuracy: 0.9375WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0186s vs `on_train_batch_end` time: 0.3010s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.6027 - accuracy: 0.9102\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 29s 4s/step - loss: 5.6027 - accuracy: 0.9102 - val_loss: 3.2585 - val_accuracy: 0.9430\n",
      "epoch  22\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 6.1427 - accuracy: 0.9375 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0493s vs `on_train_batch_end` time: 0.2974s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 4.3572 - accuracy: 0.9297\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 28s 3s/step - loss: 4.3572 - accuracy: 0.9297 - val_loss: 5.4743 - val_accuracy: 0.9127\n",
      "epoch  23\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 9.3792 - accuracy: 0.9062 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0180s vs `on_train_batch_end` time: 0.3013s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 5.9297 - accuracy: 0.9219\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 27s 3s/step - loss: 5.9297 - accuracy: 0.9219 - val_loss: 6.3967 - val_accuracy: 0.9063\n",
      "epoch  24\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 8.9787 - accuracy: 0.9062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0181s vs `on_train_batch_end` time: 0.3001s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 6.2507 - accuracy: 0.9297\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 27s 3s/step - loss: 6.2507 - accuracy: 0.9297 - val_loss: 4.2685 - val_accuracy: 0.9423\n",
      "epoch  25\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 8.1586 - accuracy: 0.9062WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0207s vs `on_train_batch_end` time: 0.3020s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 7.3288 - accuracy: 0.8945\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 28s 3s/step - loss: 7.3288 - accuracy: 0.8945 - val_loss: 3.6363 - val_accuracy: 0.9210\n",
      "epoch  26\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 11.5431 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0150s vs `on_train_batch_end` time: 0.2979s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 6.9820 - accuracy: 0.9180\n",
      "Epoch 00001: val_loss did not improve from 1.92995\n",
      "8/8 [==============================] - 28s 3s/step - loss: 6.9820 - accuracy: 0.9180 - val_loss: 2.8602 - val_accuracy: 0.9173\n",
      "epoch  27\n",
      "2/8 [======>.......................] - ETA: 1s - loss: 7.5444 - accuracy: 0.8906 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0195s vs `on_train_batch_end` time: 0.2962s). Check your callbacks.\n",
      "8/8 [==============================] - ETA: 0s - loss: 6.6234 - accuracy: 0.9023"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-84f4458e96c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mix_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     score = gender_model.fit(train_x[ix_train], train_y[ix_train],\n\u001b[0m\u001b[1;32m     17\u001b[0m         epochs=1, validation_data=(test_x, test_y), callbacks=[checkpointer])\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1121\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1123\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1124\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "scores = []\n",
    "epochs = 250; batch_size = 256\n",
    "\n",
    "# 101 classes so categorical cross entropy - but have to read once again\n",
    "gender_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='gender_model.hdf5',monitor='val_loss',\n",
    "                verbose=1, save_best_only=True, mode='auto')\n",
    "\n",
    "for i in range(epochs):\n",
    "    print(\"epoch \",i)\n",
    " \n",
    "    ix_train = np.random.choice(train_x.shape[0], size=batch_size)\n",
    " \n",
    "    score = gender_model.fit(train_x[ix_train], train_y[ix_train],\n",
    "        epochs=1, validation_data=(test_x, test_y), callbacks=[checkpointer])\n",
    "\n",
    "scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 [==============================] - 22s 236ms/step - loss: 3.9337 - accuracy: 0.9453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.933727264404297, 0.9453333616256714]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_model.evaluate(test_x, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 657,   83],\n",
       "       [  81, 2179]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    " \n",
    "predictions = gender_model.predict(test_x)\n",
    " \n",
    "pred_list = []; actual_list = []\n",
    " \n",
    "for i in predictions:\n",
    "    pred_list.append(np.argmax(i))\n",
    "\n",
    "for i in test_y:\n",
    "    actual_list.append(np.argmax(i))\n",
    "\n",
    "confusion_matrix(actual_list, pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
